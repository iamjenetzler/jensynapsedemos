{
	"name": "Notebook 3",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "13da1f96-9265-41dc-b2d4-47ec44f9a595"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from mmlspark.cognitive import *\n",
					"from notebookutils import mssparkutils\n",
					"\n",
					"\n",
					"# Load the data into a Spark DataFrame\n",
					"df = spark.sql(\"SELECT * FROM default.anomaly_detector_testing_data\")\n",
					"\n",
					"anomalyDetector = (SimpleDetectAnomalies()\n",
					"    .setLinkedService(\"pbifinance_anomolydetector\")\n",
					"    .setOutputCol(\"output\")\n",
					"    .setErrorCol(\"error\")\n",
					"    .setGranularity(\"monthly\")\n",
					"    .setTimestampCol(\"timestamp\")\n",
					"    .setValueCol(\"value\")\n",
					"    .setGroupbyCol(\"group\"))\n",
					"\n",
					"results = anomalyDetector.transform(df)\n",
					"\n",
					"# Show the results\n",
					"display(results.select(\"timestamp\", \"value\", \"group\", \"output.*\", \"error\").limit(10))"
				],
				"execution_count": null
			}
		]
	}
}